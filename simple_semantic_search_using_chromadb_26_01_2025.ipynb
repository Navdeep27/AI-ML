{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navdeep27/AI-ML/blob/Training/simple_semantic_search_using_chromadb_26_01_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct5Lt3L0jFrw",
        "outputId": "4a5cac4b-0485-4d1e-e9f5-10f232f12f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.20.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install chromadb sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Step 1: Initialize ChromaDB Client\n",
        "# Removed the 'chroma_db_impl' setting from Settings\n",
        "client = chromadb.Client(chromadb.config.Settings(\n",
        "    persist_directory=\"./chromadb_data\"  # Directory to store the database\n",
        "))\n",
        "\n",
        "# Step 2: Set up a ChromaDB Collection\n",
        "collection_name = \"semantic_search\"\n",
        "if collection_name not in client.list_collections():\n",
        "    collection = client.create_collection(name=collection_name)\n",
        "else:\n",
        "    collection = client.get_collection(name=collection_name)\n",
        "\n",
        "# Step 3: Embed and Insert Documents\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Pre-trained model for embeddings\n",
        "documents = [\n",
        "    \"Milvus is a vector database.\",\n",
        "    \"Semantic search is a powerful technique.\",\n",
        "    \"Machine learning models can create embeddings.\",\n",
        "    \"Vector search finds relevant documents.\"\n",
        "]\n",
        "\n",
        "# Generate embeddings for the documents\n",
        "embeddings = model.encode(documents).tolist()\n",
        "\n",
        "# Add documents to the collection\n",
        "ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
        "metadata = [{\"source\": f\"Document {i+1}\"} for i in range(len(documents))]\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    embeddings=embeddings,\n",
        "    metadatas=metadata,\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "# Step 4: Perform Semantic Search\n",
        "query = \"How does vector search work?\"\n",
        "query_embedding = model.encode([query]).tolist()[0]\n",
        "\n",
        "# Search the collection for top 3 similar results\n",
        "results = collection.query(\n",
        "    query_embeddings=[query_embedding],\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "# Step 5: Display Results\n",
        "print(\"Search Results:\")\n",
        "for i, (doc, score, meta) in enumerate(zip(results[\"documents\"][0], results[\"distances\"][0], results[\"metadatas\"][0])):\n",
        "    print(f\"{i+1}. Text: {doc} | Score: {1 - score:.4f} | Source: {meta['source']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bVxV7g-jHbk",
        "outputId": "3103002e-65f0-488e-f22a-dbbbbf7c5af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Results:\n",
            "1. Text: Vector search finds relevant documents. | Score: 0.3185 | Source: Document 4\n",
            "2. Text: Semantic search is a powerful technique. | Score: -0.0947 | Source: Document 2\n",
            "3. Text: Milvus is a vector database. | Score: -0.1120 | Source: Document 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.delete_collection(name=collection_name)"
      ],
      "metadata": {
        "id": "KaBdr-CQlB6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}